/**
 * Layer 3: Auto-Generated Caption Processing
 * 
 * Special handling for auto-generated captions.
 * Applies cleanup and merging to improve quality of ASR output.
 */

import type { TranscriptSegment, TranscriptResult, TranscriptMetadata } from '@pauser/common';
import { TranscriptStatus, ExtractionLayer } from '@pauser/common';

/**
 * Common filler patterns in auto-generated captions
 * These are preserved but can be identified for filtering
 */
const CONTENT_MARKERS = [
  '[Music]',
  '[Applause]',
  '[Laughter]',
  '[Silence]',
  '[Inaudible]',
  '[ __ ]', // Censored expletive
  '[BLANK_AUDIO]',
];

/**
 * Patterns that indicate low-quality ASR output
 */
const NOISE_PATTERNS = [
  /^(um|uh|ah|eh|hmm|hm|oh|mm)+$/i,
  /^\s*-\s*$/,
  /^\.+$/,
];

/**
 * Check if segment is mostly filler/noise
 */
function isNoiseSegment(text: string): boolean {
  const trimmed = text.trim().toLowerCase();
  
  // Very short segments without meaningful content
  if (trimmed.length < 2) return true;
  
  // Check noise patterns
  for (const pattern of NOISE_PATTERNS) {
    if (pattern.test(trimmed)) return true;
  }
  
  return false;
}

/**
 * Check if segment is a content marker (preserve these)
 */
function isContentMarker(text: string): boolean {
  const upperText = text.trim().toUpperCase();
  return CONTENT_MARKERS.some(marker => 
    upperText.includes(marker.toUpperCase())
  );
}

/**
 * Clean auto-generated caption text
 */
function cleanAutoText(text: string): string {
  let result = text;
  
  // Remove leading/trailing dashes common in auto-captions
  result = result.replace(/^[-–—]\s*/g, '');
  result = result.replace(/\s*[-–—]$/g, '');
  
  // Fix common ASR mistakes
  result = result
    // "i" -> "I" when standalone
    .replace(/\bi\b/g, 'I')
    // Add period after common sentence endings if missing
    .replace(/\b(okay|alright|right|yes|no|well)\s*$/i, '$1.')
    // Normalize quotation marks
    .replace(/[""]/g, '"')
    .replace(/['']/g, "'");
  
  return result.trim();
}

/**
 * Merge very short fragments into coherent segments
 * Auto-captions often split words or phrases unnecessarily
 */
function mergeShortFragments(
  segments: TranscriptSegment[],
  minDurationSeconds: number = 1.0,
  maxGapSeconds: number = 0.5
): TranscriptSegment[] {
  if (segments.length === 0) return [];
  
  const merged: TranscriptSegment[] = [];
  let buffer: TranscriptSegment[] = [];
  
  const flushBuffer = () => {
    if (buffer.length === 0) return;
    
    const combined: TranscriptSegment = {
      startTime: buffer[0].startTime,
      endTime: buffer[buffer.length - 1].endTime,
      rawText: buffer.map(s => s.rawText).join(' ').replace(/\s+/g, ' ').trim(),
      cleanedText: buffer.map(s => s.cleanedText).join(' ').replace(/\s+/g, ' ').trim(),
    };
    
    merged.push(combined);
    buffer = [];
  };
  
  for (const segment of segments) {
    // Check if this segment should start a new group
    if (buffer.length > 0) {
      const lastSegment = buffer[buffer.length - 1];
      const gap = segment.startTime - lastSegment.endTime;
      const bufferDuration = lastSegment.endTime - buffer[0].startTime;
      
      // Flush if gap is too large or buffer is long enough
      if (gap > maxGapSeconds || bufferDuration >= minDurationSeconds * 2) {
        flushBuffer();
      }
    }
    
    buffer.push(segment);
    
    // Check if buffer duration meets minimum
    const bufferDuration = segment.endTime - buffer[0].startTime;
    if (bufferDuration >= minDurationSeconds) {
      // Check if we're at a natural break (ends with punctuation)
      if (/[.!?]$/.test(segment.cleanedText)) {
        flushBuffer();
      }
    }
  }
  
  // Flush remaining
  flushBuffer();
  
  return merged;
}

/**
 * Process auto-generated captions to improve quality
 */
export function processAutoGeneratedCaptions(segments: TranscriptSegment[]): TranscriptSegment[] {
  if (segments.length === 0) return [];
  
  // Step 1: Filter out pure noise segments (but keep content markers)
  let processed = segments.filter(segment => {
    if (isContentMarker(segment.cleanedText)) return true;
    return !isNoiseSegment(segment.cleanedText);
  });
  
  // Step 2: Clean text in each segment
  processed = processed.map(segment => ({
    ...segment,
    cleanedText: cleanAutoText(segment.cleanedText),
  }));
  
  // Step 3: Merge very short fragments
  processed = mergeShortFragments(processed, 1.0, 0.5);
  
  // Step 4: Second pass of cleaning after merge
  processed = processed.map(segment => ({
    ...segment,
    cleanedText: segment.cleanedText
      .replace(/\s+/g, ' ')
      .trim(),
  }));
  
  return processed;
}

/**
 * Layer 3: Process auto-generated captions
 * 
 * This layer is called when we have auto-generated captions
 * and want to improve their quality.
 */
export async function extractWithAutoProcessing(
  rawSegments: TranscriptSegment[],
  videoId: string,
  languageCode: string,
  languageName: string
): Promise<TranscriptResult> {
  console.log('[Pauser] Layer 3: Processing auto-generated captions...');
  
  try {
    // Process the segments
    const processedSegments = processAutoGeneratedCaptions(rawSegments);
    
    if (processedSegments.length === 0) {
      return {
        status: TranscriptStatus.UNAVAILABLE,
        segments: [],
        metadata: null,
        error: 'No usable segments after processing',
        extractionLayer: ExtractionLayer.AUTO_CAPTIONS,
      };
    }
    
    const lastSegment = processedSegments[processedSegments.length - 1];
    
    const metadata: TranscriptMetadata = {
      videoId,
      language: languageName || 'Auto-generated',
      languageCode: languageCode || 'en',
      isAutoGenerated: true,
      isTranslated: false,
      fetchedAt: Date.now(),
      totalDuration: lastSegment.endTime,
      segmentCount: processedSegments.length,
    };
    
    console.log(`[Pauser] Layer 3: Processed ${rawSegments.length} -> ${processedSegments.length} segments`);
    
    return {
      status: TranscriptStatus.READY,
      segments: processedSegments,
      metadata,
      extractionLayer: ExtractionLayer.AUTO_CAPTIONS,
    };
  } catch (error) {
    console.error('[Pauser] Layer 3 processing failed:', error);
    return {
      status: TranscriptStatus.ERROR,
      segments: [],
      metadata: null,
      error: error instanceof Error ? error.message : 'Unknown error',
      extractionLayer: ExtractionLayer.AUTO_CAPTIONS,
    };
  }
}
